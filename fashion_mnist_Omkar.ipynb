{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import numpy as np\n",
    "import torch\n",
    "import codecs\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MNIST(data.Dataset):\n",
    "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
    "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "    class_to_idx = {_class: i for i, _class in enumerate(classes)}\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        if self.train:\n",
    "            return self.train_labels\n",
    "        else:\n",
    "            return self.test_labels\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = torch.load(\n",
    "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
    "        else:\n",
    "            self.test_data, self.test_labels = torch.load(\n",
    "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
    "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "        from six.moves import urllib\n",
    "        import gzip\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        # download files\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        for url in self.urls:\n",
    "            print('Downloading ' + url)\n",
    "            data = urllib.request.urlopen(url)\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(data.read())\n",
    "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                    gzip.GzipFile(file_path) as zip_f:\n",
    "                out_f.write(zip_f.read())\n",
    "            os.unlink(file_path)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n",
    "\n",
    "\n",
    "class FashionMNIST(MNIST):\n",
    "    \"\"\"`Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    class_to_idx = {_class: i for i, _class in enumerate(classes)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "train_dataset=FashionMNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset=FashionMNIST(root='./data',train=False,transform=transforms.ToTensor(),download=True)\n",
    "batch_size=100\n",
    "n_iters=18000\n",
    "num_epochs=n_iters/(len(train_dataset)/batch_size)\n",
    "num_epochs=int(num_epochs)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)\n",
    "class CNNModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super (CNNModule,self).__init__()\n",
    "\n",
    "        # Convolution 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1,padding=2)\n",
    "        # nn.Dropout2d(p=0.5, inplace=False)\n",
    "        self.relu1=nn.ReLU()                  # ELU()\n",
    "        ### nn.init.xavier_uniform(self.cnn1.weight)\n",
    "        self.conv1_bn = nn.BatchNorm2d(16)\n",
    "        nn.init.xavier_uniform_(self.cnn1.weight)\n",
    "        # nn.functional.dropout2d(16, p=0.5, training=False, inplace=False)\n",
    "        #Max pool 1\n",
    "        # nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 2\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.cnn2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1,padding=2)\n",
    "        # nn.Dropout2d(p=0.5, inplace=False)\n",
    "        self.relu2=nn.ReLU()                 # ELU()\n",
    "        ### nn.init.xavier_uniform(self.cnn2.weight)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        nn.init.xavier_uniform_(self.cnn2.weight)\n",
    "        # nn.functional.dropout2d(32, p=0.5, training=False, inplace=False)\n",
    "        # nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # Max pool 2\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # self.relu3=nn.ReLU()\n",
    "        # self.dropout = nn.Dropout2d(p=0.5, inplace=False)\n",
    "        \n",
    "        # Convolution 3\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.cnn3 = nn.Conv2d(in_channels= 32, out_channels= 64, kernel_size=5,stride=1, padding=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        #          self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        nn.init.xavier_uniform_(self.cnn3.weight)\n",
    "        self.MaxPool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Fully connected 1\n",
    "        self.fcl=nn.Linear(576,10)          # 2 layers= 32*7*7\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.cnn1(x)\n",
    "        out=self.relu1(out)\n",
    "        out = self.conv1_bn(out)\n",
    "        \n",
    "        out=self.maxpool1(out)\n",
    "        \n",
    "        out=self.cnn2(out)\n",
    "        out=self.relu2(out)\n",
    "        out = self.conv2_bn(out)\n",
    "        out=self.maxpool2(out)\n",
    "        # out size (100,32,7,7)\n",
    "        # feed (100,32*7*7) to linear fn\n",
    "        \n",
    "        # out=self.relu3(out)\n",
    "        # out=self.dropout(out)\n",
    "        \n",
    "        out= self.cnn3(out)\n",
    "        out = self.relu3(out)\n",
    "        # out = self.conv3_bn(out)\n",
    "        out = self.conv3_bn(out)\n",
    "        out = self.MaxPool3(out)\n",
    "        \n",
    "         \n",
    "        \n",
    "        out=out.view(out.size(0),-1)\n",
    "        \n",
    "        out=self.fcl(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNNModule()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate=0.03  #0.03\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omkar/Installed/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 500. Loss: 0.4482528269290924. Accuracy: 87.49\n",
      "Iterations: 1000. Loss: 0.30650967359542847. Accuracy: 88.21\n",
      "Iterations: 1500. Loss: 0.2996268570423126. Accuracy: 89.22\n",
      "Iterations: 2000. Loss: 0.3496604561805725. Accuracy: 89.42999999999999\n",
      "Iterations: 2500. Loss: 0.21620315313339233. Accuracy: 89.24\n",
      "Iterations: 3000. Loss: 0.2786029875278473. Accuracy: 89.86\n",
      "Iterations: 3500. Loss: 0.18519149720668793. Accuracy: 89.42\n",
      "Iterations: 4000. Loss: 0.19128048419952393. Accuracy: 90.45\n",
      "Iterations: 4500. Loss: 0.2202489823102951. Accuracy: 90.14999999999999\n",
      "Iterations: 5000. Loss: 0.12852789461612701. Accuracy: 89.98\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):                        # 5 fold times\n",
    "    for i, (images,labels) in enumerate(train_loader): # all 60000 images\n",
    "        #load images as variables\n",
    "        #images = Variable(images.view(-1,28*28))\n",
    "        ##### using images = images.reshape(-1,28*28)\n",
    "        #labels = Variable(labels)\n",
    "        #clear gradients wrt parameters\n",
    "        images=Variable(images)\n",
    "        labels=Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        #forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        #calculate loss--> softmax to cross entropy loss\n",
    "        loss = criterion(outputs , labels)\n",
    "        #getting gradients wrt parameters\n",
    "        loss.backward()\n",
    "        #updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter+=1\n",
    "        \n",
    "        #new for logistic regression\n",
    "        if iter%500==0:\n",
    "            #calculate accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # iterate through test dataset\n",
    "            for images,labels in test_loader:\n",
    "                #load images to torch Variable\n",
    "                images = Variable(images)\n",
    "                #forward pass only to get output\n",
    "                outputs = model(images)\n",
    "                #get predictions from the max value\n",
    "                _,predicted = torch.max(outputs.data,1)\n",
    "                #total num of labels\n",
    "                total += labels.size(0)\n",
    "                #total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100*(float(correct)/total)\n",
    "            \n",
    "            #print loss\n",
    "            print (\"Iterations: {}. Loss: {}. Accuracy: {}\".format(iter,loss.data[0], accuracy))           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
