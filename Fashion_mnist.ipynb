{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import numpy as np\n",
    "import torch\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(data.Dataset):\n",
    "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
    "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "    class_to_idx = {_class: i for i, _class in enumerate(classes)}\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        if self.train:\n",
    "            return self.train_labels\n",
    "        else:\n",
    "            return self.test_labels\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = torch.load(\n",
    "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
    "        else:\n",
    "            self.test_data, self.test_labels = torch.load(\n",
    "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
    "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "        from six.moves import urllib\n",
    "        import gzip\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        # download files\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        for url in self.urls:\n",
    "            print('Downloading ' + url)\n",
    "            data = urllib.request.urlopen(url)\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(data.read())\n",
    "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                    gzip.GzipFile(file_path) as zip_f:\n",
    "                out_f.write(zip_f.read())\n",
    "            os.unlink(file_path)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n",
    "\n",
    "\n",
    "class FashionMNIST(MNIST):\n",
    "    \"\"\"`Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    class_to_idx = {_class: i for i, _class in enumerate(classes)}\n",
    "\n",
    "def get_int(b):\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "\n",
    "def read_label_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2049\n",
    "        length = get_int(data[4:8])\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "        return torch.from_numpy(parsed).view(length).long()\n",
    "\n",
    "\n",
    "def read_image_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2051\n",
    "        length = get_int(data[4:8])\n",
    "        num_rows = get_int(data[8:12])\n",
    "        num_cols = get_int(data[12:16])\n",
    "        images = []\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "    return torch.from_numpy(parsed).view(length, num_rows, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "train_dataset=FashionMNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset=FashionMNIST(root='./data',train=False,transform=transforms.ToTensor(),download=True)\n",
    "batch_size=100\n",
    "n_iters=18000\n",
    "num_epochs=n_iters/(len(train_dataset)/batch_size)\n",
    "num_epochs=int(num_epochs)\n",
    "# load data\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super (CNNModule,self).__init__()\n",
    "\n",
    "        # Convolution 1\n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1,padding=2)\n",
    "        # nn.Dropout2d(p=0.5, inplace=False)\n",
    "        self.relu1=nn.ReLU()                  # SELU()\n",
    "        self.conv1_bn = nn.BatchNorm2d(16)\n",
    "        nn.init.xavier_uniform_(self.cnn1.weight)\n",
    "        \n",
    "        #Max pool 1\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 2\n",
    "        \n",
    "        self.cnn2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1,padding=2)\n",
    "        # nn.Dropout2d(p=0.5, inplace=False)\n",
    "        self.relu2=nn.ReLU()                 # SELU()\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        nn.init.xavier_uniform_(self.cnn2.weight)\n",
    "        \n",
    "        # Max pool 2\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 3\n",
    "        \n",
    "        self.cnn3 = nn.Conv2d(in_channels= 32, out_channels= 64, kernel_size=5,stride=1, padding=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        nn.init.xavier_uniform_(self.cnn3.weight)\n",
    "        \n",
    "        # Max pool 3\n",
    "        self.maxPool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        \n",
    "        # Fully connected network\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(576, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "        \"\"\"\n",
    "        # Fully connected 1\n",
    "        self.fcl=nn.Linear(576,10)          # 2 layers= 32*7*7\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.cnn1(x)\n",
    "        out=self.relu1(out)\n",
    "        out = self.conv1_bn(out)\n",
    "        \n",
    "        out=self.maxpool1(out)\n",
    "        \n",
    "        out=self.cnn2(out)\n",
    "        out=self.relu2(out)\n",
    "        out = self.conv2_bn(out)\n",
    "        out=self.maxpool2(out)\n",
    "        \n",
    "        # out size (100,32,7,7)\n",
    "        # feed (100,32*7*7) to linear fn\n",
    "        \n",
    "        # out=self.dropout(out)\n",
    "        \n",
    "        out= self.cnn3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.conv3_bn(out)\n",
    "        out = self.maxPool3(out)\n",
    "        \n",
    "         \n",
    "        \n",
    "        out=out.view(out.size(0),-1)\n",
    "        \n",
    "        out=self.fcl(out)\n",
    "        # out = self.classifier(out)\n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNNModule()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate=0.03  #0.03\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omkar/Installed/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 500. Loss: 0.2875724136829376. Accuracy: 86.76\n",
      "Iterations: 1000. Loss: 0.287662535905838. Accuracy: 88.53999999999999\n",
      "Iterations: 1500. Loss: 0.186595618724823. Accuracy: 89.09\n",
      "Iterations: 2000. Loss: 0.39148885011672974. Accuracy: 89.07000000000001\n",
      "Iterations: 2500. Loss: 0.1426483690738678. Accuracy: 89.63\n",
      "Iterations: 3000. Loss: 0.22725093364715576. Accuracy: 90.41\n",
      "Iterations: 3500. Loss: 0.2617591917514801. Accuracy: 90.77\n",
      "Iterations: 4000. Loss: 0.15027019381523132. Accuracy: 90.59\n",
      "Iterations: 4500. Loss: 0.1257735937833786. Accuracy: 90.27\n",
      "Iterations: 5000. Loss: 0.1373767852783203. Accuracy: 90.64\n",
      "Iterations: 5500. Loss: 0.1377425640821457. Accuracy: 90.60000000000001\n",
      "Iterations: 6000. Loss: 0.12841109931468964. Accuracy: 90.99000000000001\n",
      "Iterations: 6500. Loss: 0.1065763533115387. Accuracy: 90.51\n",
      "Iterations: 7000. Loss: 0.18179963529109955. Accuracy: 90.47\n",
      "Iterations: 7500. Loss: 0.09633537381887436. Accuracy: 90.12\n",
      "Iterations: 8000. Loss: 0.10868176817893982. Accuracy: 90.0\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):                        # 5 fold times\n",
    "    for i, (images,labels) in enumerate(train_loader): # all 60000 images\n",
    "        #load images as variables\n",
    "        #images = Variable(images.view(-1,28*28))\n",
    "        ##### using images = images.reshape(-1,28*28)\n",
    "        #labels = Variable(labels)\n",
    "        #clear gradients wrt parameters\n",
    "        images=Variable(images)\n",
    "        labels=Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        #forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        #calculate loss--> softmax to cross entropy loss\n",
    "        loss = criterion(outputs , labels)\n",
    "        #getting gradients wrt parameters\n",
    "        loss.backward()\n",
    "        #updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter+=1\n",
    "        \n",
    "        #new for logistic regression\n",
    "        if iter%500==0:\n",
    "            #calculate accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # iterate through test dataset\n",
    "            for images,labels in test_loader:\n",
    "                #load images to torch Variable\n",
    "                images = Variable(images)\n",
    "                #forward pass only to get output\n",
    "                outputs = model(images)\n",
    "                #get predictions from the max value\n",
    "                _,predicted = torch.max(outputs.data,1)\n",
    "                #total num of labels\n",
    "                total += labels.size(0)\n",
    "                #total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100*(float(correct)/total)\n",
    "            \n",
    "            #print loss\n",
    "            print (\"Iterations: {}. Loss: {}. Accuracy: {}\".format(iter,loss.data[0], accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
